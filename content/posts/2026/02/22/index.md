---
title: "ZettelkastenをRAGの情報源として有効活用するには、ノート間のリンクに型付きエッジを持たなければならない"
date: 2026-02-22T00:00:00+0900
author: "sonohen"
categories: ["Architecture"]
tags: ["Generative AI", "Personal-Knowledge-Management"]
description: ZettelkastenをClaudeのRAG情報源として接続しようとしたとき、ノート間のリンクに意味がないとAIがネットワークを無制限にトラバースしてしまう。この問題の本質を検討し、それに対する取り組みとしての「型付きエッジ (relation-typed edges)」という設計アプローチについて整理する。この方法論により、使用トークン数は70%削減、エージェント数は67%削減、回答品質はほぼ同じか上がったという結論を得た。
---

※ この記事は、誤字脱字、表現の冗長さ・曖昧さのチェックのためにClaude Codeを利用しています。

## TL;DR

- 本記事で提案する「手動による型付きエッジの付与による運用」は、GraphRAGやNeo4j RAGとは異なり、型付きエッジを手動で付与する。これにより、Zettelkastenの探索を人間の手によって制御し、かつインフラの運用コストを抑えることができる点に差別化要素がある。
- ZettelkastenをRAGの情報源として使う場合、**ノート間のリンクに型付きエッジを付与しなければ、AIはグラフを無限に辿ってコンテキストが膨張する** 。
- 人間はリンクの意味をノートの文脈から推測できるが、AIにはその判断ができない。これは「人間にとってわかりやすいリンクはAIにとって分からない」という構造的な非対称性である。
- データの意味付けを軽視してきた歴史（セマンティックウェブ、ビッグデータ、企業RAG）は、同じ失敗パターンの繰り返しだと解釈できる。
- 付与する型付きエッジとして `supports →` / `contradicts →` / `refines →` / `depends_on →` の4種を提案する。
- コンテキストが膨張するとOOMによるクラッシュ（MLX）や推論崩壊（llama.cpp）が起きる。これは設計の問題であり、パラメータ調整で解決できるものではない。
- 実際に計測したところ、型付きエッジによる制約付きグラフ探索（constrained graph traversal）でトークン使用量を約70%削減（556,006 → 163,782トークン）しながら、回答品質をほぼ維持できることを確認した。
- ただし、リンクに対する型付きエッジの付与だけが解決策ではない。どこを意味付けし、どこをしないかという全体設計が必要である。

## なぜ、ノート間（リンク）の関係を自動抽出ではなく手動で行うのか（はじめに）

GraphRAG[^2] や、Neo4j RAGのような手法では、異なる2つのエンティティ間の関係を自動抽出し、型付きエッジを持つグラフを構築する。本記事の提案は、これらと同じくグラフのトラバーサルを意味的に制御するものであるが、設計の前提が異なる。

第一に、ZettelkastenのAI（Claude）による自動操作はすでに試みており、失敗している。AIにノートの作成・メタデータ付与・構造操作を任せた結果、ノイズが混入し、知的生産の基盤としての機能を失った（詳細は『[Zettelkastenを機能させ、また形骸化させないために、何でもかんでも入れるべきではない](../../../2026/01/25/)』を参照）。Zettelkastenは自分の思考の蓄積であり、AIによる自動操作とは相容れない。

第二に、インフラコストの問題がある。GraphRAG/Neo4j RAGはグラフDBや埋め込みモデルの常時稼働を前提とし、個人が複数台の端末間で使い回すには重すぎる。本記事の設計は、ObsidianのMarkdownファイルとClaude(MCP)のみで完結し、端末を問わず持ち運べることを条件としている。

つまり、手動による型付きエッジの付与を選んだのは、自動化の限界を実体験した結果と、軽量・ポータブルであるという制約条件の両方によるものである。この選択におけるGraphRAGとの差分は「自動か手動か」だけでなく、「運用環境の重さ」と「Zettelkastenの思想との整合性」にある。

[^2]: Edge, Darren, Ha Trinh, Newman Cheng, ほか. 「From Local to Global: A Graph RAG Approach to Query-Focused Summarization」. arXiv:2404.16130. 査読前原稿, arXiv, 2025年2月19日. [https://doi.org/10.48550/arXiv.2404.16130](https://doi.org/10.48550/arXiv.2404.16130).

## きっかけ

『[ローカルLLMでSpec Driven Developmentは、まだ難しかった](../../../2026/02/14/)』という記事を書きながら、「自分のZettelkastenをRAGの情報源として接続すれば、自分の思考を元にした回答が得られるのではないか」という考えが浮かんだ。

ただし、この設計を考えるにあたって、一つの前提がある。過去にAIにノート操作を任せた結果、Zettelkastenがノイズだらけになるという失敗を経験している（『[Zettelkastenで管理する情報は何で、どう管理すべきなのか](../../../2026/01/25/)』、『[Zettelkastenを機能させ、また形骸化させないために、何でもかんでも入れるべきではない。](../../../2026/01/31/)』）。その経験から、「AIはZettelkastenを読むことはできるが書いてはいけない」という原則をすでに確立している。今回の設計はその原則の上に成り立っている。

しかし、実際に試そうとした瞬間、問題が見えてきた。Zettelkastenのノートはネットワーク型の構造になっており、ノート間には無数のリンクが張り巡らされている。RAGとして使うということは、AIがそのネットワークを辿ってコンテキストを組み立てることになるが、「どのリンクをどこまで辿るか」という制御をどうするかが難しい。

そこで少し考えてみると、問題の本質は「ノート間に型付きエッジが付与されていない」ことだということに気がついた。

## ZettelkastenとRAGの相性問題

そもそもRAGとは何かを整理しておく。RAGは、LLMが一般的な訓練データから回答を生成するのではなく、特定のドキュメント群（情報源）を参照しながら回答する仕組みだ。ハルシネーションの影響範囲を限定し、特定ドメインに閉じた回答を得るための構造設計の方法論として使われる。具体的には、Zettelkastenとの組み合わせで期待できるのは、「自分の思考・知識を格納したナレッジベースを、AIが参照しながら回答できるようになること」だ。

ところが、ZettelkastenをそのままRAGとして活用すると問題が起きる。Zettelkastenのノートはそれぞれが他のノートへのリンクを持っており、関連するノートをどんどん参照する構造になっている。AIがネットワークを辿り始めると、関連ノートをすべて読み込もうとしてしまい、コンテキストが際限なく膨張する。

これは設計の問題だ。**RAGという文脈においては、どのリンクをどこまで辿るかを制御する「制約付きグラフ探索」がなければ、Zettelkastenは有用な情報源にならない** のである。

## リンクの「意味」は、人間は理解でき、AIには理解できない

リンクの制約付きグラフ探索の問題は、「このリンクは辿るべきか、辿らなくてよいか」をどう判断するか、である。

人間はノートを読みながら、リンクの意味を文脈から推測できる。「このリンクは根拠として貼ったもの」「このリンクは反論の候補として貼ったもの」「このリンクは前提知識として必要なもの」といった区別を、リンクを貼った瞬間に理解している。

しかし、AIにはそれが分からない。リンクはただの接続であり、その接続が「支持」なのか「反論」なのか「依存」なのかを、ただのリンクから読み解くことはできないのである。

```
[人間の場合]
ノートA ──リンク──> ノートB
          ↑
  「これは根拠ノートだ」と文脈から判断できる

[AIの場合]
ノートA ──リンク──> ノートB
          ↑
  意味が分からない。全部辿るしかない。
```

これは「人間にとってわかりやすいリンクはAIにとって分からない」という構造的な非対称性だ。この非対称性を放置したまま「ZettelkastenをRAGに使う」という設計は、機能しない。本質的には『[「顧客はわかっていない」を構造的に再解釈する](../../../2026/02/1503/)』で議論した内容と同じである。

## データの意味付けを後回しにしてきた歴史

この問題は、実は繰り返されてきた「うまくいかない」パターンと同じ構造を持っている。

### (1) セマンティックウェブ

Web 2.0の台頭で、膨大な個人メディアがウェブに溢れたとき、ティム・バーナーズ・リーは、RDFやOWLといったメタデータ技術によって情報に意味を付与する「セマンティックウェブ」を提唱した。機械が情報の意味を解釈し、より賢い検索・統合ができるようにするというビジョンだった。

しかし、広くは普及しなかった。既存の膨大なデータにメタデータを付与するコストが、得られるメリットに見合わなかったからだ。現在はベクトル検索との共存という形で、その理念が部分的に受け継がれている。

![メタデータを活用している例](./images/20260222111045.png)

### (2) ビッグデータ

Hadoopなどのデータ分析基盤が「大量のデータに価値がある」という前提で作られた時代、データの意味付けはないがしろにされた。データが何を意味しているのかが分からない状態で分析を行い、期待通りの洞察は得られなかった。

### (3) 企業におけるRAG活用

現在も同じパターンが繰り返されている。企業内に存在するExcelやPowerPointといった非定型データをRAGに登録しても、望む回答精度が得られないという課題がある。原因は単純で、ドキュメント内の要素がどのような文脈でどのような意味を持つのかを、AIが理解できないからだ。意味付けのない情報をいくら積み上げても、AIはそれを有効に活用できない。

**情報の蓄積に価値があるという幻想と、意味付けのコストを軽視してきた結果が、この繰り返しである** と私は考えている。この課題を解決しようとしている企業が多く存在していることからも、今回は同じ繰り返しをしないようにしていると考えられる。

## 型付きエッジを付与したリンクの提案

この構造的な非対称性を解消するために、リンクに「型付きエッジを付与する」設計を考えた。リンクの種類を以下の4つに分類し、リンクを貼る際に明示的に意味付けを行う。

| 型              | 意味                     | 用途                                           |
| --------------- | ------------------------ | ---------------------------------------------- |
| `supports →`    | このノートの根拠         | 主張の根拠を支えるノートへのリンク             |
| `contradicts →` | このノートへの反論       | 反論・対立する視点へのリンク                   |
| `refines →`     | このノートの洗練・具体化 | 上位・下位概念の関係、より詳細な説明へのリンク |
| `depends_on →`  | このノートの前提条件     | 読む前に理解すべき前提知識へのリンク           |

実際の記述例はこうなる。

```markdown
## 主張

ZettelkastenをRAGの情報源として有効活用するには、ノート間のリンクには型付きエッジを付与する必要がある。

- supports → [[人間にとってわかりやすいリンクは、AIにとっては分からない]]
  - context: 人間はリンクの意味を文脈から推測できるが、AIはできない。

- depends_on → [[Zettelkastenのノート間のリンクは型付きエッジによって意味づけしておくことが重要]]
  - context: 型付きエッジがなければ、AIはグラフを無限に探索してしまう。
```

この設計をすることで、制約付きグラフ探索が可能になる。たとえば「`supports`リンクだけを辿る」「`depends_on`は1ホップまで」といったルールをクエリ時に適用できるようになる。

なお、`contradicts`リンクが多いノートは、未解決の領域あるいは思考の臨界点を示していることになる。これはAIへの指示の文脈だけでなく、ノートを管理する人間にとっても有用な情報になる。

ただし、この方法には、型付きエッジを後から付与するためのコストが爆発的に増えるという課題がある。

## 制約付きグラフ探索の効果を計測する

提案している設計の効果を確認するために、実際にトークン使用量を計測した。170ノート・41,370文字・207リンクで構成されたZettelkastenを対象に、「生成AIにおけるRAGの現状と課題」を調査するタスクをClaude Codeに依頼し、制約付きグラフ探索によってどれほど差が出るかを比較した。

| 条件                   | サブエージェント実行数 | トークン使用量               |
| ---------------------- | ---------------------- | ---------------------------- |
| 制約付きグラフ探索なし | 12回                   | 556,006トークン              |
| 制約付きグラフ探索あり | 4回（約67%削減）       | 163,782トークン（約70%削減） |

なしの場合、AIはすべてのリンクを辿るために12のサブエージェントを起動し、55万トークン超を消費した。ありの場合は、型付きエッジをもとに必要なノードに絞り込み、4エージェント・16万トークン強で完了した。

回答品質についても比較した。

| 回答事項                                           | 制約付きグラフ探索あり | 制約付きグラフ探索なし |
| -------------------------------------------------- | ---------------------- | ---------------------- |
| 1. RAGの本質的な役割（Vaultが示す再定義）          | 回答あり               | 回答あり               |
| 2. 実装アーキテクチャの変遷（実体験ベース）        | 回答あり               | 回答あり               |
| 3. AI Engineer ／ Application Developer の責任境界 | 回答あり               | 回答あり               |
| 4. ベクトル検索とメタデータの共存                  | _回答なし_ [^1]        | 回答あり               |
| 課題1：データ意味付けの困難さ（最重要課題）        | 回答あり               | 回答あり               |
| 課題2：コンテキスト長の膨張と推論エンジンへの影響  | 回答あり               | 回答あり               |
| 課題3：リンク意味の不透明性                        | 回答あり               | 回答あり               |
| 課題4：AI／人間の判断境界設計                      | 回答あり               | 回答あり               |
| 課題5：データ更新・削除の複雑性                    | 回答あり               | 回答あり               |
| 課題6：机上設計と実装の乖離                        | 回答あり               | 回答あり               |
| 課題7：歴史的失敗の反復リスク                      | _回答なし_ [^1]        | 回答あり               |

[^1]: 制約付きグラフ探索ありで「回答なし」となった項目は、型付きエッジによって選ばれたノート群が中心的な問いに絞り込まれた結果、AIが回答対象として設定しなかったものである。カバレッジの欠落ではなく、焦点化の結果と解釈している。

ありで「ベクトル検索とメタデータの共存」「歴史的失敗の反復リスク」の2項目が未回答となったが、これは型付きエッジによって選ばれたノード群が中心的な問いに絞り込まれた結果であり、カバレッジの欠落ではなく焦点化の結果と解釈している。

トークン使用量を約70%削減しながら回答品質をほぼ維持できたことは、制約付きグラフ探索の有効性を裏付けている。また、データを絞ることでAIが中心的な問いにフォーカスするという副作用も確認できた。コンテキストの膨張は「情報量が多ければ回答の質が上がる」という直感に反し、むしろ回答品質を下げる可能性があることを示唆している。

## コンテキスト膨張は実害を生む

これは概念的な話ではなく、『[ローカルLLMでSpec Driven Developmentは、まだ難しかった](../../../2026/02/14/)』で身をもって経験した実害でもある。コンテキストが膨張すると、推論エンジンはOOM（Out of Memory）に陥る。その挙動はエンジンによって異なる。

- **MLX（mlx_lm）**: OOMが発生した時点でクラッシュする。これ以降の推論崩壊を防ぐための設計だが、処理が中断される。
- **llama.cpp**: OOM後も `ctx_pos` / `n_past` が進み続け、初期化が保証されていないKV Cacheを参照しながら推論を続けてしまう。結果として推論崩壊が起きる。

どちらが良い悪いではなく、設計思想のトレードオフだ。しかし、いずれにしてもコンテキストを膨張させないことが根本的な解決策であり、制約付きグラフ探索はその手段の一つになる。

## 課題

制約付きグラフ探索は一つの解だが、リンクだけを整備すれば十分というわけではない。ノート内のどの部分がAIにとって「文脈」として有効なのか、何をZettelkastenにおけるメタデータに含めるべきか、ノート自体にどのようなメタデータを持たせるかといった設計の問いは、リンクに対して型付きエッジを付与した後にも残る。**型付きエッジの付与は「設計行為」であり、どこを付与し、どこをしないかという全体像を先に決めなければ、部分最適に終わる** という考えである。

また、既存の大量のノートに型付きエッジを後から付与するコストも現実的な障壁だ。セマンティックウェブが普及しなかった理由の一つが「既存データへのメタデータ付与コスト」だったこと、GraphRAGが自動で検出を試みていることの2つを考えると、新規ノートから型付きエッジを付け始めて様子を見るスモールスタートが現実的だろうと考えている。

## まとめ

- ZettelkastenをRAGの情報源として接続するには、ノート間のリンクに型付きエッジが必要である。型付きエッジがなければ、AIがグラフを無限にトラバースしてコンテキストが膨張する。実際の計測では、型付きエッジをもとにした制約付きグラフ探索なしで556,006トークン・12エージェントだったのに対し、ありでは163,782トークン・4エージェントに抑制できた（それぞれ約70%・約67%の削減）。
- これはデータに対する型付きエッジの付与を軽視してきた歴史（セマンティックウェブ、ビッグデータ、企業RAG）と同じ構造である。情報の蓄積には価値があるが、意味付けなき蓄積は、AIがそれを有効活用できないという点で、「何を蓄積するか」以上に重要な論点になる。
- Zettelkastenのノート間のリンクに意味付けを行うという点においては、`supports →` / `contradicts →` / `refines →` / `depends_on →` の4種の型付きエッジを提案する。これにより制約付きグラフ探索が可能になると考えている。
- コンテキスト膨張はOOMクラッシュや推論崩壊という実害を生む。これはパラメータ調整ではなく、設計で解決すべき問題である。
- リンクの型付きエッジは解決策の一部であり、全体の意味付け設計と合わせて考える必要がある。
  - リンクの型付きエッジは、双方向リンクに対しては爆発的にコストが大きくなる。片方向だけで十分かどうかも含めて検討する必要がある。
